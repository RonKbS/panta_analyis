{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1268      0.172\n1269      0.131\n1270           \n1271    300.862\nName: april, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# GET JUST THE PREVIOUS MONTH'S data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('allData_19042021_export.json')\n",
    "df_2021 = df.loc[df['year'] == 2021]\n",
    "old_data_df = pd.read_csv(\"Cloud_SQL_Export_2021-04-12 (19_47_25).csv\")\n",
    "# print(len(old_data_df.index))\n",
    "\n",
    "df_rows = []\n",
    "indicators = ['field_ndvi', 'field_ndwi', 'field_rainfall', 'field_temperature']\n",
    "for index, row in df_2021.iterrows():\n",
    "    for indicator in indicators:\n",
    "        df_row = {}\n",
    "        row_2021 = df_2021.loc[df_2021['field_id'] == row['field_id']]\n",
    "        df_row['field_id']= row['field_id']\n",
    "        df_row['indicator'] = indicator\n",
    "        for key, value in row[indicator].items():\n",
    "        # for key, value in json.loads(row[indicator]).items():\n",
    "            df_row[key] = value\n",
    "        df_rows.append(df_row)\n",
    "        \n",
    "df2 = pd.DataFrame(df_rows)\n",
    "\n",
    "for index, row in old_data_df.iterrows():\n",
    "    try:\n",
    "        value_ = df2[\"march\"].loc[(df2[\"field_id\"] == row[\"field_id\"]) & (df2[\"indicator\"] == row[\"indicator\"])]\n",
    "        # if not value_.empty:\n",
    "        if value_.values[0]:\n",
    "            old_data_df.loc[index, \"march\"] = float(value_.values[0])\n",
    "            # row[\"march\"] = float(value_.values[0])\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "old_data_df.to_csv(\"updated_march.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "14it [00:00, 171.51it/s]56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GET LAST 12 MONTH'S DATA\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# data = geopandas.read_file(\"crops.geojson\")\n",
    "# data.head() # show the first 5 rows of the data.\n",
    "\n",
    "df = pd.read_json('farmafrica_data_can_finally_move_on.json')\n",
    "df_2020 = df.loc[df['year'] == 2020]\n",
    "df_2021 = df.loc[df['year'] == 2021]\n",
    "\n",
    "df_rows = []\n",
    "indicators = ['field_ndvi', 'field_ndwi', 'field_rainfall', 'field_temperature']\n",
    "for index, row in tqdm(df_2020.iterrows()):\n",
    "    for indicator in indicators:\n",
    "        df_row = {}\n",
    "        row_2021 = df_2021.loc[df_2021['field_id'] == row['field_id']]\n",
    "        df_row['field_id']= row['field_id']\n",
    "        # df_row['user_id']= row['user_id']\n",
    "        df_row['indicator'] = indicator\n",
    "        for key, value in row[indicator].items():\n",
    "        # for key, value in json.loads(row[indicator]).items():\n",
    "            df_row[key] = value\n",
    "            if key in [\"january\", \"february\", \"march\"]:\n",
    "                df_row[key] = row_2021[indicator].iloc[0][key]\n",
    "            # if key == \"january\":\n",
    "            #     df_row[key] = row_2021[indicator].iloc[0][key]\n",
    "            # elif key == \"february\" and indicator != \"field_rainfall\":\n",
    "            #     df_row[key] = row_2021[indicator].iloc[0][key]\n",
    "\n",
    "        df_rows.append(df_row)\n",
    "\n",
    "df2 = pd.DataFrame(df_rows)\n",
    "print(len(df2.index))\n",
    "# df2.replace('', np.nan, regex=True, inplace=True)\n",
    "# df2.dropna(how='all', axis='columns', inplace=True)\n",
    "# print(f\"2021 data length is {len(df.index)}\")\n",
    "# df2.iloc[0]\n",
    "# df2.iloc[0]['may']\n",
    "# print(len(df2.index))\n",
    "# df2.to_csv(\"jan_feb_data.csv\", index=False)\n",
    "df2.to_json('formatted_farmafrica_data_can_finally_move_on.json', orient='records')\n",
    "# print(\"doneeeee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Exercises\n",
    "\n",
    "These exercises will be used to evaluate your ability to work with geospatial data in Python. You will need several python packages to complete these exercises, the packages required are as follows:\n",
    "\n",
    "* geopandas\n",
    "* pandas\n",
    "* rasterio\n",
    "* fiona\n",
    "* ) == 1144636.0, \"Sorry wrong answer\"\n",
    "# # assert str(reproject_raster('crops.tif', 'EPSG:4326').crs) == 'EPSG:4326', \"Sorry wrong answer\"\n",
    "# print(\"Congratulations, all is working just fine !!!\")\n",
    "\n",
    "For each cell where you see \"WRITE YOUR CODE HERE\" delete the return notImplemented statement when you write your code there - don't leave it in the notebook. This notebook contains test cases to evaluate whether your functions are working correctly. When you run these cells they will print either \"Congratulations, all is working just fine !!!\" if your function works or \"Sorry wrong answer\" if it does not. Once you finish these exercises, upload the completed notebook to the application page and submit your application.\n",
    "\n",
    "In case of any questions, contact the organizers at hello@radiant.earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data using GeoPandas\n",
    "[GeoPandas](https://geopandas.org/) is a Python library that is particularly good for doing any geospatial-data-related tasks in Python. We will use several other libraries in Python as well.\n",
    "\n",
    "To test that everything is working fine:\n",
    "1. Ensure that all of the files from the repository are in the same directory as this notebook.\n",
    "2. Use GeoPandas to read in the first sheet of data from the geojson file as shown below\n",
    "3. Work through some of the example analyses shown and complete the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\ml4eo\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CropType\n",
       "Cabbage         154\n",
       "Cucumber          1\n",
       "Eggplant         74\n",
       "Okra              9\n",
       "Onion            76\n",
       "Pumpkin          45\n",
       "Sweet Pepper     18\n",
       "Watermelon       68\n",
       "Name: field_id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# FINDING AREA FOR FIELDS IN A GEOJSON GROUPED TOGETHER\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "\n",
    "gdf = geopandas.read_file(\"field_poygons_eastwest.json\")\n",
    "\n",
    "# gdf.iloc[0]['field_attributes']['CropType']\n",
    "\n",
    "gdf= gdf.to_crs({'init': 'epsg:3857'})\n",
    "gdf['CropType'] = gdf['field_attributes'].apply(pd.Series)['CropType']\n",
    "\n",
    "gdf = gdf[gdf['CropType']!='Tomato']\n",
    "gdf['Area'] = gdf['geometry'].area\n",
    "# gdf.head()\n",
    "\n",
    "gdf.groupby(['CropType'])['Area'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]\n",
      "\n",
      " {'system:index': '0_00000000000000000015', 'field_id': 'e00d7e2a-7ebb-4b33-946b-d5f7961d954c', 'field_ndvi': 0.287836492061615, 'field_ndwi': 0.2380281686782837, 'field_rainfall': 2.4969465732574463, 'field_temperature': 299.2894897460937} <class 'float'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "sentinel_df = pd.read_csv(\"east_west_sentinel_data.csv\")\n",
    "precip_df = pd.read_csv(\"east_west_precipitation_data.csv\")\n",
    "temp_df = pd.read_csv(\"east_west_temperature_data.csv\")\n",
    "\n",
    "months = [\n",
    "    \"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "    \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"\n",
    "]\n",
    "\n",
    "df_rows = []\n",
    "for index, row in tqdm(sentinel_df.iterrows()):\n",
    "    df_row = {}\n",
    "\n",
    "    year_month = int(row[\"system:index\"].split(\"_\")[0])\n",
    "    if year_month < 11:\n",
    "        df[\"year\"] = 2020\n",
    "    else:\n",
    "        df[\"year\"] = 2021\n",
    "    df_row[\"mot\"]\n",
    "    # df_row[\"system:index\"] = row[\"system:index\"]\n",
    "    df_row[\"field_id\"] = row[\"field_id\"]\n",
    "    precip_row = precip_df.loc[precip_df[\"system:index\"] == row[\"system:index\"]]\n",
    "    temp_row = temp_df.loc[temp_df[\"system:index\"] == row[\"system:index\"]]\n",
    "    df_row[\"field_ndvi\"] = row[\"NDVI_mean\"]\n",
    "    df_row[\"field_ndwi\"] = row[\"NDWI_mean\"]\n",
    "    # print(\"\\n\", precip_row[\"mean\"].iloc[0].item(), \"\\n\\n\", type(precip_row[\"mean\"].iloc[0].item()))\n",
    "    df_row[\"field_rainfall\"] = precip_row.iloc[0][\"mean\"].item() if not precip_row.empty else None\n",
    "    df_row[\"field_temperature\"] = temp_row.iloc[0][\"mean\"].item() if not temp_row.empty else None\n",
    "    print(\"\\n\\n\",df_row, type(df_row[\"field_temperature\"]))\n",
    "    df_rows.append(df_row)\n",
    "    break\n",
    "\n",
    "df2 = pd.DataFrame(df_rows)\n",
    "df2.to_csv(\"random_data.csv\", index=False)\n",
    "df2.head()\n",
    "# print(sentinel_df.columns)\n",
    "# precip_df.columns\n",
    "# print(\n",
    "#     len(sentinel_df.index), len(precip_df.index)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "This dataset contains field boundaries for crop fields in Kenya as well as the crop types present. Each field can have multiple crops present and are represented in the \"Crop1\", \"Crop2\", \"Crop3\", \"Crop4\", and \"Crop5\" columns. Each record also has the date the survey was conducted, when the crops were planted, an estimated harvest date, and whether the planting date is an estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing all of the different types of crops present in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Cassava',\n",
       " 'Maize',\n",
       " 'Sorghum',\n",
       " 'Bean',\n",
       " 'Groundnut',\n",
       " 'Fallowland',\n",
       " 'Millet',\n",
       " 'Tomato',\n",
       " 'Sugarcane',\n",
       " 'Sweetpotato',\n",
       " 'Banana',\n",
       " '',\n",
       " 'Cowpea',\n",
       " 'Soybean']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "list(pd.unique(data[['Crop1', 'Crop2', 'Crop3', 'Crop4', 'Crop5']].values.ravel('K')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For you to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4892"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Write your code to complete the following functions\n",
    "\n",
    "def get_crop_area(crop):\n",
    "    # Calculate the total area in square meters of the fields which contain the selected crop\n",
    "    selected_fields = data.loc[\n",
    "        (data['Crop1'] == crop) | (data['Crop2'] == crop) |\n",
    "        (data['Crop3'] == crop) | (data['Crop4'] == crop) | (data['Crop5'] == crop)\n",
    "    ]\n",
    "    # print(f\"Number of fields with this crop are {len(selected_fields.index)}\")\n",
    "    # print(f\"\\nTotal number of fields are {len(data.index)}\")\n",
    "    # # This is already in squeare meters. According to the GIS stackexchange link in this cell\n",
    "    selected_fields['area (sqm)'] = selected_fields['geometry'].area\n",
    "    # # print(selected_fields.area.round(2).head())\n",
    "    # print(f\"\\nTotal area for selected fields is {int(selected_fields.area.sum())}\")\n",
    "    \n",
    "    #TODO Figure out which coordinate system was used.\n",
    "    # Seems like its already in a coordinate system, basing on this -> https://gis.stackexchange.com/a/218453\n",
    "    \n",
    "    # WRITE YOUR CODE HERE\n",
    "    area = int(selected_fields.area.sum())\n",
    "    return area\n",
    "\n",
    "get_crop_area(\"Bean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Congratulations, all is working just fine !!!\n"
     ]
    }
   ],
   "source": [
    "# Run this to validate your function works correctly\n",
    "\n",
    "assert int(get_crop_area('Maize')) == 192534, \"Sorry wrong answer\"\n",
    "assert int(get_crop_area('Sorghum')) == 227, \"Sorry wrong answer\"\n",
    "assert int(get_crop_area('Banana')) == 946, \"Sorry wrong answer\"\n",
    "print(\"Congratulations, all is working just fine !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Bonus questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import pycrs\n",
    "\n",
    "\n",
    "def masked_raster(input_file, raster_file):\n",
    "    # Create a masked version of the input raster where pixels falling within one of the fields are set to `1` and pixels outside the fields are set to `0`\n",
    "    \n",
    "    # WRITE YOUR CODE HERE\n",
    "\n",
    "    out_img = rasterio.open(raster_file).read()\n",
    "    return out_img\n",
    "\n",
    "def reproject_raster(raster_file, dst_crs):\n",
    "    # Reproject the input raster to the provided CRS\n",
    "    \n",
    "    src = rasterio.open(raster_file)\n",
    "    \n",
    "    with rasterio.open(raster_file) as src:\n",
    "        transform, width, height = rasterio.warp.calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })  \n",
    "        \n",
    "        split_name = raster_file.split(\".\")[0]\n",
    "        out_file_name =f\"{split_name}_projected.tif\"\n",
    "        with rasterio.open(out_file_name, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                rasterio.warp.reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=rasterio.warp.Resampling.nearest)\n",
    "                \n",
    "        # dst = src\n",
    "        return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'EPSG:4326'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "str(reproject_raster('crops.tif', 'EPSG:4326').crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Sorry wrong answer",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f06544a79625>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run this to validate your function works correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(masked_raster('crops.geojson', 'crops.tif')[0].sum())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mmasked_raster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'crops.geojson'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'crops.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1144636.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sorry wrong answer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreproject_raster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'crops.tif'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EPSG:4326'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'EPSG:4326'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sorry wrong answer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Congratulations, all is working just fine !!!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Sorry wrong answer"
     ]
    }
   ],
   "source": [
    "# Run this to validate your function works correctly\n",
    "# print(masked_raster('crops.geojson', 'crops.tif')[0].sum())\n",
    "# assert masked_raster('crops.geojson', 'crops.tif')[0].sum() == 1144636.0, \"Sorry wrong answer\"\n",
    "assert str(reproject_raster('crops.tif', 'EPSG:4326').crs) == 'EPSG:4326', \"Sorry wrong answer\"\n",
    "print(\"Congratulations, all is working just fine !!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd0e6868cda821e825435848912e2aada3070bc7a8a84aa5bcbcb97c731119e320d",
   "display_name": "Python 3.9.2 64-bit ('ml4eo': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}